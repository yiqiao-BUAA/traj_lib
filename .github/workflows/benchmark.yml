# .github/workflows/benchmark.yml
name: Benchmark CI

on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [main]

jobs:
  parse-and-test:
    if: startsWith(github.event.pull_request.title, '[bench]')
    runs-on: [self-hosted]         # æœ¬åœ° GPU/CPU runner æ ‡ç­¾
    timeout-minutes: 120

    steps:
    - uses: actions/checkout@v4
      with:
        submodules: recursive

    # -------- â‘  è§£æ PR æ ‡é¢˜ â†’ æä¾›é»˜è®¤å€¼ --------
    - name: Extract benchmark args
      id: args
      shell: bash
      run: |
        title="${{ github.event.pull_request.title }}"

        # é»˜è®¤å€¼
        model=""
        dataset="all"
        metrics="all"

        for kv in $title; do
          [[ $kv =~ model=(.*)   ]] && model="${BASH_REMATCH[1]}"
          [[ $kv =~ dataset=(.*) ]] && dataset="${BASH_REMATCH[1]}"
          [[ $kv =~ metrics=(.*) ]] && metrics="${BASH_REMATCH[1]}"
        done

        if [[ -z "$model" ]]; then
          echo >&2 "âŒ PR æ ‡é¢˜ç¼ºå°‘ model=<name>"
          exit 1
        fi

        printf "model=%s\ndataset=%s\nmetrics=%s\n" \
               "$model" "$dataset" "$metrics" >> "$GITHUB_OUTPUT"

    # -------- â‘¡ å®‰è£… & è¿è¡ŒåŸºå‡† --------
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install root requirements
      if: hashFiles('requirements.txt') != ''
      run: pip install -r requirements.txt
    
    - name: Install model-specific requirements
      run: |
        MODEL_DIR="traj_lib/model/${{ steps.args.outputs.model }}"
        REQ_FILE="${MODEL_DIR}/requirements.txt"
        if [ -f "$REQ_FILE" ]; then
          echo "ğŸ“¦ Installing deps for $REQ_FILE"
          pip install -r "$REQ_FILE"
        fi

    - name: Run benchmark
      env:
        MODEL:   ${{ steps.args.outputs.model }}
        DATASET: ${{ steps.args.outputs.dataset }}
        METRICS: ${{ steps.args.outputs.metrics }}
      run: |
        python -m traj_lib.main \
          --model   "$MODEL" \
          --dataset "$DATASET" \
          --metrics "$METRICS"

    # -------- â‘¢ ä¿å­˜ç»“æœä¾›åç»­ workflow_run ä½¿ç”¨ --------
    - uses: actions/upload-artifact@v4
      with:
        name: bench-result
        path: traj_lib/outputs/**/*.json
