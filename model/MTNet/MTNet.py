import collections
from typing import Any

import dgl
import torch
import torch.nn as nn

from utils.exargs import ParseDict
from .MTNet_utils import construct_MobilityTree, handle_data

SSTBatch = collections.namedtuple(
    "SSTBatch", ["graph", "features", "time", "label", "mask", "mask2", "type"]
)


class IntraHierarchyCommunication(nn.Module):
    def __init__(self, embedding_dim: int, h_size: int, nary: int):
        super(IntraHierarchyCommunication, self).__init__()
        self.nary = nary
        self.W_f = nn.Linear(
            embedding_dim, h_size, bias=False
        )  # W_f -> [embedding_dim, h_size]
        self.U_f = nn.Linear(nary * h_size, nary * h_size, bias=False)
        self.b_f = nn.Parameter(torch.zeros(1, h_size))
        self.W_iou = nn.Linear(
            embedding_dim, 3 * h_size, bias=False
        )  # [W_i, W_u, W_o] -> [embedding_dim, 3 * h_size]
        self.U_iou = nn.Linear(nary * h_size, 3 * h_size, bias=False)
        self.b_iou = nn.Parameter(torch.zeros(1, 3 * h_size))
        # Transformer encoder
        encoder_layers = nn.TransformerEncoderLayer(h_size, 2, h_size, 0.4)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, 2)

    def apply_node_func(self, nodes: Any) -> dict[str, torch.Tensor]:
        iou = nodes.data["iou"]
        i, o, u = torch.chunk(iou, 3, 1)
        i, o, u = torch.sigmoid(i), torch.sigmoid(o), torch.tanh(u)
        c = i * u + nodes.data["c"]  # [batch, h_size]
        h = o * torch.tanh(c)
        return {"h": h, "c": c}

    def message_func(self, edges: Any) -> dict[str, torch.Tensor]:
        return {
            "h_child": edges.src["h"],
            "c_child": edges.src["c"],
            "type": edges.src["type"],
        }

    def reduce_func(self, nodes: Any) -> dict[str, torch.Tensor]:
        Wx = torch.cat([self.W_f(nodes.data["x"]) for _ in range(self.nary)], dim=1)
        b_f = torch.cat([self.b_f for _ in range(self.nary)], dim=1)
        h_cat = nodes.mailbox["h_child"]  # [batch, nary, h_size]
        h_cat = h_cat.view(h_cat.size(0), -1)  # [batch, nary * h_size]
        f = torch.sigmoid(Wx + self.U_f(h_cat) + b_f)
        h_cat_att = self.transformer_encoder(nodes.mailbox["h_child"])
        h_cat_att = h_cat_att.view(h_cat_att.size(0), -1)
        iou = (
            self.W_iou(nodes.data["x"]) + self.U_iou(h_cat_att) + self.b_iou
        )  # [batch, 3 * h_size]
        c = torch.sum(
            f.view(nodes.mailbox["c_child"].size()) * nodes.mailbox["c_child"], 1
        )
        return {"c": c.view(c.size(0), -1), "iou": iou}


class InterHierarchyCommunication(nn.Module):
    def __init__(self, h_size: int, nary: int):
        super(InterHierarchyCommunication, self).__init__()
        self.nary = nary
        self.W_f = nn.Linear(
            h_size, h_size, bias=False
        )  # W_f -> [embedding_dim, h_size]
        self.U_f = nn.Linear(nary * h_size, nary * h_size, bias=False)
        self.b_f = nn.Parameter(torch.zeros(1, h_size))
        self.W_iou = nn.Linear(
            h_size, 3 * h_size, bias=False
        )  # [W_i, W_u, W_o] -> [embedding_dim, 3 * h_size]
        self.U_iou = nn.Linear(nary * h_size, 3 * h_size, bias=False)
        self.b_iou = nn.Parameter(torch.zeros(1, 3 * h_size))
        # Transformer encoder
        encoder_layers = nn.TransformerEncoderLayer(h_size, 2, h_size, 0.4)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, 2)

    def apply_node_func(self, nodes: Any) -> dict[str, torch.Tensor]:
        iou = nodes.data["iou"]
        i, o, u = torch.chunk(iou, 3, 1)
        i, o, u = torch.sigmoid(i), torch.sigmoid(o), torch.tanh(u)
        c = i * u + nodes.data["c"]  # [batch, h_size]
        h = o * torch.tanh(c)
        return {"h": h, "c": c}

    def message_func(self, edges: Any) -> dict[str, torch.Tensor]:
        return {
            "h_child": edges.src["h"],
            "c_child": edges.src["c"],
            "type": edges.src["type"],
        }

    def reduce_func(self, nodes: Any) -> dict[str, torch.Tensor]:
        Wx = torch.cat([self.W_f(nodes.data["x"]) for _ in range(self.nary)], dim=1)
        b_f = torch.cat([self.b_f for _ in range(self.nary)], dim=1)
        h_cat = nodes.mailbox["h_child"]  # [batch, nary, h_size]
        h_cat = h_cat.view(h_cat.size(0), -1)  # [batch, nary * h_size]
        f = torch.sigmoid(Wx + self.U_f(h_cat) + b_f)
        h_cat_att = self.transformer_encoder(nodes.mailbox["h_child"])
        h_cat_att = h_cat_att.view(h_cat_att.size(0), -1)
        iou = (
            self.W_iou(nodes.data["x"]) + self.U_iou(h_cat_att) + self.b_iou
        )  # [batch, 3 * h_size]
        c = torch.sum(
            f.view(nodes.mailbox["c_child"].size()) * nodes.mailbox["c_child"], 1
        )
        return {"c": c.view(c.size(0), -1), "iou": iou}


class TreeLSTM(nn.Module):
    def __init__(
        self,
        h_size: int = 512,
        nary: int = 5,
        embed_dropout: float = 0.2,
        model_dropout: float = 0.4,
        num_users: int = 3000,
        user_embed_dim: int = 128,
        num_POIs: int = 5000,
        POI_embed_dim: int = 128,
        num_cats: int = 300,
        cat_embed_dim: int = 32,
        num_coos: int = 1024,
        coo_embed_dim: int = 64,
        device: str = "cuda",
    ):
        super(TreeLSTM, self).__init__()
        self.device = device
        self.h_size = h_size
        self.nary = nary
        # embedding layer
        self.embedding_dim = (
            user_embed_dim + POI_embed_dim + cat_embed_dim + coo_embed_dim
        )
        self.user_embedding = nn.Embedding(
            num_embeddings=num_users, embedding_dim=user_embed_dim
        )
        self.POI_embedding = nn.Embedding(
            num_embeddings=num_POIs, embedding_dim=POI_embed_dim
        )
        self.cat_embedding = nn.Embedding(
            num_embeddings=num_cats, embedding_dim=cat_embed_dim
        )
        self.coo_embedding = nn.Embedding(
            num_embeddings=num_coos, embedding_dim=coo_embed_dim
        )
        # positional encoding layer
        self.time_pos_encoder = nn.Embedding(
            num_embeddings=96, embedding_dim=self.embedding_dim
        )  # 24*4
        # dropout layer
        self.embed_dropout = nn.Dropout(embed_dropout)
        self.model_dropout = nn.Dropout(model_dropout)
        # LSTM cell
        self.cell_IAC = IntraHierarchyCommunication(self.embedding_dim, h_size, nary)
        self.cell_IRC = InterHierarchyCommunication(h_size, nary)
        # decoder layer
        self.decoder_POI = nn.Linear(h_size, num_POIs)
        self.decoder_cat = nn.Linear(h_size, num_cats)
        self.decoder_coo = nn.Linear(h_size, num_coos)

    def forward(
        self, MT_input: SSTBatch
    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        user_embedding = self.user_embedding(
            MT_input.features[:, 0].long() * MT_input.mask
        )
        POI_embedding = self.POI_embedding(
            MT_input.features[:, 1].long() * MT_input.mask
        )
        cat_embedding = self.cat_embedding(
            MT_input.features[:, 2].long() * MT_input.mask
        )
        coo_embedding = self.coo_embedding(
            MT_input.features[:, 3].long() * MT_input.mask
        )
        pe = self.time_pos_encoder(MT_input.time.long() * MT_input.mask)
        concat_embedding = torch.cat(
            (user_embedding, POI_embedding, cat_embedding, coo_embedding), dim=1
        )
        concat_embedding = concat_embedding + pe * 0.5

        g = MT_input.graph.to(self.device)
        n = g.num_nodes()
        g.ndata["iou"] = self.cell_IAC.W_iou(
            self.embed_dropout(concat_embedding)
        ) * MT_input.mask.float().unsqueeze(-1)
        g.ndata["x"] = self.embed_dropout(
            concat_embedding
        ) * MT_input.mask.float().unsqueeze(-1)
        g.ndata["h"] = torch.zeros((n, self.h_size)).to(self.device)
        g.ndata["c"] = torch.zeros((n, self.h_size)).to(self.device)
        g.ndata["h_child"] = torch.zeros((n, self.nary, self.h_size)).to(self.device)
        g.ndata["c_child"] = torch.zeros((n, self.nary, self.h_size)).to(self.device)

        dgl.prop_nodes_topo(
            graph=g,
            message_func=self.cell_IAC.message_func,
            reduce_func=self.cell_IAC.reduce_func,
            apply_node_func=self.cell_IAC.apply_node_func,
        )

        h_1 = g.ndata["h"]  # [batch_size, h_size]
        g.ndata["x"] = h_1 * MT_input.mask2.float().unsqueeze(-1)

        dgl.prop_nodes_topo(
            graph=g,
            message_func=self.cell_IRC.message_func,
            reduce_func=self.cell_IRC.reduce_func,
            apply_node_func=self.cell_IRC.apply_node_func,
        )

        h_2 = self.model_dropout(g.ndata["h"])  # [batch_size, h_size]

        y_pred_POI = self.decoder_POI(h_2)
        y_pred_cat = self.decoder_cat(h_2)
        y_pred_coo = self.decoder_coo(h_2)

        return y_pred_POI, y_pred_cat, y_pred_coo


class MultiTaskLoss(nn.Module):
    def __init__(self, num: int = 3):
        super(MultiTaskLoss, self).__init__()
        params = torch.ones(num, requires_grad=True)
        self.params = nn.Parameter(params)

    def forward(self, *losses: torch.Tensor) -> torch.Tensor:
        loss_sum = torch.Tensor([0.0]).to(self.params.device)
        for i, loss in enumerate(losses):
            loss_sum += 0.5 * torch.exp(-self.params[i]) * loss + self.params[i]
        return loss_sum


class MTNet(nn.Module):
    def __init__(self, args: ParseDict):
        super().__init__()

        num_pois = args.num_pois
        num_users = args.num_users
        num_poi_cats = args.num_poi_cats
        num_regions = args.num_regions

        self.n_time_slot = args.n_time_slot
        self.plot_tree = args.plot_tree
        self.device = args.device

        self.TreeLSTM_model = TreeLSTM(
            h_size=args.h_size,
            nary=args.n_time_slot + 1,
            embed_dropout=args.embed_dropout,
            model_dropout=args.model_dropout,
            num_users=num_users,
            user_embed_dim=args.user_embed_dim,
            num_POIs=num_pois,
            POI_embed_dim=args.POI_embed_dim,
            num_cats=num_poi_cats,
            cat_embed_dim=args.cat_embed_dim,
            num_coos=num_regions,
            coo_embed_dim=args.coo_embed_dim,
            device=args.device,
        ).to(device=args.device)

        self.criterion_POI = nn.CrossEntropyLoss(ignore_index=-1)  # -1 is ignored
        self.criterion_cat = nn.CrossEntropyLoss(ignore_index=-1)
        self.criterion_coo = nn.CrossEntropyLoss(ignore_index=-1)
        self.multi_task_loss = MultiTaskLoss(num=3)

    def get_MT_input(self, batch_data: dict[str, Any], test: bool = False) -> SSTBatch:
        trajectories_list, labels_list = handle_data(batch_data, self.n_time_slot, test)

        MT_batcher = []
        for trajectory, labels in zip(trajectories_list, labels_list):
            mobility_tree = construct_MobilityTree(
                trajectory, labels, self.n_time_slot + 1
            )
            MT_batcher.append(mobility_tree.to(self.device))

        MT_batch = dgl.batch(MT_batcher).to(self.device)

        MT_input = SSTBatch(
            graph=MT_batch,
            features=MT_batch.ndata["x"].to(self.device),
            time=MT_batch.ndata["time"].to(self.device),
            label=MT_batch.ndata["y"].to(self.device),
            mask=MT_batch.ndata["mask"].to(self.device),
            mask2=MT_batch.ndata["mask2"].to(self.device),
            type=MT_batch.ndata["type"].to(self.device),
        )
        return MT_input

    def forward(self, batch_data: dict[str, Any]) -> torch.Tensor:
        MT_input = self.get_MT_input(batch_data)

        y_pred_POI, y_pred_cat, y_pred_coo = self.TreeLSTM_model(MT_input)
        y_POI, y_cat, y_coo = (
            MT_input.label[:, 0],
            MT_input.label[:, 1],
            MT_input.label[:, 2],
        )

        loss_POI = self.criterion_POI(y_pred_POI, y_POI.long())
        loss_cat = self.criterion_cat(y_pred_cat, y_cat.long())
        loss_coo = self.criterion_coo(y_pred_coo, y_coo.long())
        loss = self.multi_task_loss(loss_POI, loss_cat, loss_coo)

        return loss

    def predict(self, batch_data: dict[str, Any]) -> torch.Tensor:
        MT_input = self.get_MT_input(batch_data, test=True)

        y_pred_POI, _, _ = self.TreeLSTM_model(MT_input)
        y_POI = MT_input.label[:, 0]

        row_indices = torch.where(y_POI != -1)[0].cpu()
        ind1 = torch.where(MT_input.type == 0)[0].cpu()
        row = torch.tensor([idx for idx in row_indices if idx in ind1])
        y_POI = y_POI[row]
        y_pred_POI_day_node = y_pred_POI[row]
        ind2 = torch.where(MT_input.type == 1)[0].cpu()
        row2 = torch.tensor([idx for idx in row_indices if idx in ind2])
        y_pred_POI_period_node = y_pred_POI[row2]
        ind3 = torch.where(MT_input.type == 2)[0].cpu()
        row3 = torch.tensor([idx for idx in row_indices if idx in ind3])
        y_pred_POI_last_POI = y_pred_POI[row3]
        y_pred_POI = y_pred_POI_period_node + y_pred_POI_day_node + y_pred_POI_last_POI

        return y_pred_POI
